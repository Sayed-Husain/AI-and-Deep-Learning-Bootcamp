{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (NLP) with TensorFlow: Sentiment Analysis on IMDB Reviews\n",
        "\n"
      ],
      "metadata": {
        "id": "5jcZsfCg3Fk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing (NLP)\n",
        "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language. NLP encompasses a wide range of tasks, from text analysis and sentiment classification to machine translation and text generation. It aims to bridge the gap between human language and machine understanding, enabling computers to process and derive meaning from textual data."
      ],
      "metadata": {
        "id": "FO7rvdB7jLfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KBJ4Nl7RguUd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Sayed-Husain/AI-and-Deep-Learning-Bootcamp/main/Data/IMDB%20Dataset.csv\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xCzo7pL_jcnr",
        "outputId": "c78443c4-52ac-460d-f139-732da9197e83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6856cc5e-6c96-4bbe-a3f2-d719109a8bd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6856cc5e-6c96-4bbe-a3f2-d719109a8bd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6856cc5e-6c96-4bbe-a3f2-d719109a8bd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6856cc5e-6c96-4bbe-a3f2-d719109a8bd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c66b4b5b-b637-4b4f-8209-5fa7c421a509\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c66b4b5b-b637-4b4f-8209-5fa7c421a509')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c66b4b5b-b637-4b4f-8209-5fa7c421a509 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(df.sentiment.value_counts());"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "QBSUqOXzjkf0",
        "outputId": "4ddb037e-7876-469f-b50e-5d68165cba6e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding NLP, TextVectorization, and Embedding\n"
      ],
      "metadata": {
        "id": "DIypXkdAmVLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TextVectorization\n",
        "TextVectorization is a preprocessing technique in NLP that converts raw text data into numerical vectors that can be used as input for machine learning models. It involves several steps:\n",
        "\n",
        "1. **Tokenization**: Text is split into individual words or subwords, known as tokens. or example, the sentence \"I love NLP\" might be tokenized into [\"I\", \"love\", \"NLP\"].\n",
        "\n",
        "2. **Vocabulary Building:** A vocabulary is created by mapping each unique token to a unique integer index. The vocabulary captures the set of all tokens present in the dataset.\n",
        "\n",
        "3. **Vectorization:** Each text sample is represented as a sequence of integer indices corresponding to the tokens in the vocabulary. These sequences can be of fixed or variable lengths.\n",
        "\n",
        "TextVectorization helps transform raw text data into a format that machine learning models can understand and process. It prepares the data for tasks like sentiment analysis, text classification, and more."
      ],
      "metadata": {
        "id": "ZdQegaCCj9ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create the TextVectorization and specify the size of the vocabulary\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(20000) # Number of the vocabulary"
      ],
      "metadata": {
        "id": "s8u4ke_NjUaN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Adapt (Create the vocabulary list)\n",
        "text_vectorizer.adapt(df.review)"
      ],
      "metadata": {
        "id": "3Y-3IfUIkHpo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"Hi, I am an AI developer\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mcp6O36kHuj",
        "outputId": "7e4907c7-b3fa-45af-ce8f-887d2b02a898"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[ 7869,    10,   227,    34, 14739,     1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To confirm, lets take a random review and tokenize it\n",
        "import random\n",
        "\n",
        "random_sentence = random.choice(df.review)\n",
        "print(\"Original Sentence: \" + random_sentence)\n",
        "print(\"Tokenized Version: \")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjEgOTEek8ah",
        "outputId": "ecbbc185-43e8-4a4b-ae07-855eeb13e38f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: I remember this movie in particular when I was a teenager, my best friend was telling me all about this movie and how it freaked her out as a kid. Of course being the blood thirsty gal that I am, I had to go out and find this movie. Now I don't know how to put this without loosing credibility, so I'm just going to say it, I actually had fun watching this movie! I know that it's stupid, not the best story and beyond bloody and gruesome, but that's what I was looking for and The Dentist delivers in the scares, blood, sex, and crazy psychopaths. Sometimes I just need a fun movie like this to just let loose and get grossed out by.<br /><br />Dr. Alan Feinstone is obsessed with order and cleanliness. On the day of his wedding anniversary, he spies his wife Brooke having sex with their filthy pool man, Matt. At his dental practice, Feinstone's first patient of the day is young Jody Saunders, there for his very first dental appointment. Feinstone begins to clean Jody's teeth. Everything goes smoothly at first, until he imagines that Jody's teeth are brown and rotten. His dental pick slips, stabbing Jody in the gums. Jody's mother picks up her crying, bleeding child and leaves angrily. Feinstone sees his second patient, beauty queen April Reign. Alone with April, Feinstone sedates her with nitrous oxide so that he can fill a cavity in one of her molars. As she drifts off into unconsciousness, Feinstone imagines that she has transformed into his wife. He begins kissing and fondling her on the dental chair, then begins to choke her. April starts to cough and half-wakes up from the gas. Feinstone snaps out of his trance and quickly re-buttons April's blouse. Feinstone decides to end the day early and sends his staff and patients home. Later that night, Brooke meets Feinstone at his practice. He reveals his new Italian opera-themed patient room. He encourages Brooke to try out the room's dental chair. When she does, Feinstone binds her to the chair and sedates her with nitrous oxide. With operatic music blaring in the background, he begins to pull out Brooke's teeth. Feinstone has gone off the deep end and is definitely not going to let anybody stand in his way of cleanliness.<br /><br />Honestly, as silly as this movie sounds, I did have a lot of fun watching The Dentist. The best scene without a doubt is when he teaches that nasty IRS agent a lesson in hygiene that I'm sure he'll never forget. Man, I don't think I've brushed my teeth so much after I watched The Dentist. Yeah, I am going to warn you, this movie is in no way for the faint of heart, it's very bloody. There's stabbing, gun shots and just these brutal dental torture scenes that will make your stomach turn. Yet somehow I just enjoyed this movie, if I ever want just a good gore movie that was made for true horror fans, I slip it in my DVD player, and that's the \"tooth\" LOL! I am so funny! Um, yeah, I try, give me a little credit.<br /><br />7/10\n",
            "Tokenized Version: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 534), dtype=int64, numpy=\n",
              "array([[   10,   373,    11,    18,     8,   837,    51,    10,    14,\n",
              "            4,  2146,    54,   117,   446,    14,  1024,    70,    32,\n",
              "           43,    11,    18,     3,    86,     9,  9773,    42,    46,\n",
              "           15,     4,   542,     5,   260,   107,     2,   553, 16054,\n",
              "         6019,    12,    10,   227,    10,    68,     6,   139,    46,\n",
              "            3,   160,    11,    18,   149,    10,    90,   118,    86,\n",
              "            6,   264,    11,   200, 12697,  2968,    38,   142,    41,\n",
              "          162,     6,   129,     9,    10,   155,    68,   247,   146,\n",
              "           11,    18,    10,   118,    12,    30,   362,    22,     2,\n",
              "          117,    67,     3,   650,  1667,     3,  2797,    19,   175,\n",
              "           49,    10,    14,   269,    17,     3,     2,  4571,  1483,\n",
              "            8,     2,  2800,   553,   382,     3,   944, 16480,   519,\n",
              "           10,    41,   344,     4,   247,    18,    39,    11,     6,\n",
              "           41,   368,  1766,     3,    76, 15566,    46, 14705,    13,\n",
              "          788,  1774, 12937,     7,  2400,    16,   622,     3,     1,\n",
              "           21,     2,   266,     5,    25,  2043,  9365,    28,  7324,\n",
              "           25,   328,  9052,   256,   382,    16,    64,  6723,  3291,\n",
              "          132,  2208,    31,    25, 11815,  4271,     1,    88,  2473,\n",
              "            5,     2,   266,     7,   183,     1,     1,    48,    17,\n",
              "           25,    53,    88, 11815, 17929, 12937,   823,     6,  2190,\n",
              "            1,  2705,   265,   263,  8112,    31,    88,   351,    28,\n",
              "        11311,    12,     1,  2705,    24,  1876,     3,  4321,    25,\n",
              "        11815,  1195,  8556,  9174,     1,     8,     2,     1,     1,\n",
              "          431,  2902,    57,    42,  2482,  8950,   546,     3,   856,\n",
              "        17502, 12937,  1047,    25,   336,  2473,   899,  1647,  4819,\n",
              "         6173,   628,    16,  4819, 12937,     1,    42,    16,     1,\n",
              "            1,    38,    12,    28,    69,  2118,     4,     1,     8,\n",
              "           29,     5,    42,     1,    15,    59, 15291,   125,    82,\n",
              "            1, 12937, 11311,    12,    59,    45,  5440,    82,    25,\n",
              "          328,    28,   823,  5473,     3,     1,    42,    21,     2,\n",
              "        11815,  3045,    91,   823,     6, 11057,    42,  4819,   516,\n",
              "            6, 11201,     3,     1,    57,    36,     2,  2817, 12937,\n",
              "        12075,    46,     5,    25, 13686,     3,   925,     1,     1,\n",
              "        19342, 12937,  1059,     6,   130,     2,   266,   400,     3,\n",
              "         3150,    25,  3557,     3,  4257,   345,   303,    12,   315,\n",
              "         9052,   889, 12937,    31,    25,  4271,    28,  2660,    25,\n",
              "          166,  1055,     1,  2473,   691,    28,  8850,  9052,     6,\n",
              "          343,    46,     2,  4254, 11815,  3045,    51,    59,   122,\n",
              "        12937,     1,    42,     6,     2,  3045,     3,     1,    42,\n",
              "           16,     1,     1,    16, 10327,   207, 19345,     8,     2,\n",
              "          948,    28,   823,     6,  1439,    46,     1,  2705, 12937,\n",
              "           45,   776,   125,     2,   855,   130,     3,     7,   388,\n",
              "           22,   162,     6,   368,  1719,   871,     8,    25,    99,\n",
              "            5,     1,    13,  1186,    15,   668,    15,    11,    18,\n",
              "          912,    10,   114,    26,     4,   165,     5,   247,   146,\n",
              "            2,  4571,     2,   117,   131,   200,     4,   780,     7,\n",
              "           51,    28,  4754,    12,  1576, 13560,  1485,     4,  2032,\n",
              "            8,     1,    12,   142,   244,   544,   110,   820,   132,\n",
              "           10,    90,   103,   196,     1,    54,  2705,    38,    73,\n",
              "          101,    10,   279,     2,  4571,  1146,    10,   227,   162,\n",
              "            6,  3090,    23,    11,    18,     7,     8,    56,    99,\n",
              "           17,     2,  8377,     5,   534,    30,    53,  1667,   212,\n",
              "         9174,  1042,   632,     3,    41,   127,  1735, 11815,  1620,\n",
              "          135,    12,    77,    95,   123,  3023,   472,   240,   814,\n",
              "           10,    41,   498,    11,    18,    44,    10,   121,   176,\n",
              "           41,     4,    50,   636,    18,    12,    14,    93,    17,\n",
              "          287,   194,   455,    10,  6168,     9,     8,    54,   272,\n",
              "         1848,     3,   175,     2,  6876,  4834,    10,   227,    38,\n",
              "          156,  7533,  1146,    10,   343,   193,    70,     4,   116,\n",
              "            1,    13,  2479]])>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "Embedding is a fundamental concept in NLP that involves mapping words or tokens from a vocabulary to dense vectors in a continuous space. These dense vectors, known as word embeddings, capture semantic relationships between words. Word embeddings are learned from data and carry information about word meanings and relationships.\n",
        "\n",
        "In NLP models, an embedding layer is often used to map integer-encoded tokens to their corresponding word embeddings. This layer learns to associate words with vectors in such a way that similar words are closer in the embedding space. Embeddings enhance model performance by allowing it to generalize word meanings and understand relationships between words."
      ],
      "metadata": {
        "id": "lENfUmBPlin3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an embedding layer\n",
        "embedding = tf.keras.layers.Embedding(input_dim = 20000, # set input shape (the vocabulary size)\n",
        "                                     output_dim = 32) # Relationship between words (the higher the number, the more complex the relationship gets)\n"
      ],
      "metadata": {
        "id": "czCYnjG0kHys"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it, then embed it\n",
        "sample_sentence = \"Hi, I am an AI developer\"\n",
        "embedding(text_vectorizer([sample_sentence]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUQpCy9nluqv",
        "outputId": "bf720b34-aba9-4743-f650-1eaf250553c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 32), dtype=float32, numpy=\n",
              "array([[[-0.00464096,  0.03033643,  0.02118028,  0.0188549 ,\n",
              "          0.03204961, -0.00197672, -0.02679323, -0.02697771,\n",
              "         -0.03178073, -0.00915281,  0.01259855,  0.0458838 ,\n",
              "         -0.00688763,  0.03000876, -0.03463098,  0.04320988,\n",
              "         -0.01721519, -0.02018221, -0.03416524,  0.02594179,\n",
              "         -0.03320684, -0.02012844, -0.04967786,  0.02299986,\n",
              "         -0.00789645,  0.03606239,  0.04569738, -0.00754238,\n",
              "          0.00484539,  0.00658226,  0.02977129,  0.02737487],\n",
              "        [ 0.04098124, -0.01022293,  0.0002941 ,  0.00848959,\n",
              "          0.00688078, -0.02389263,  0.03927061,  0.02128396,\n",
              "         -0.02001007,  0.01012361,  0.00063753,  0.01322407,\n",
              "          0.00602251,  0.02812502,  0.0015435 , -0.01301654,\n",
              "         -0.03966885, -0.00399882,  0.00939203, -0.03183   ,\n",
              "          0.01390005,  0.01437268,  0.03362716, -0.02421597,\n",
              "         -0.04542769,  0.00772567,  0.01699675,  0.01364693,\n",
              "         -0.01400103,  0.0233208 ,  0.00246936, -0.00367321],\n",
              "        [ 0.0259029 ,  0.00928544,  0.01945439, -0.02255005,\n",
              "          0.01935348, -0.03956529, -0.03950218, -0.03789288,\n",
              "         -0.02903413, -0.01004493, -0.04779347, -0.03933185,\n",
              "         -0.04776516, -0.00524006,  0.00444625,  0.01361077,\n",
              "         -0.02241871,  0.01215871, -0.03752873,  0.0256758 ,\n",
              "         -0.00211644, -0.01380127,  0.01608369, -0.00668454,\n",
              "         -0.04450437,  0.03276924,  0.04720723,  0.013715  ,\n",
              "         -0.03043218,  0.01059996, -0.02987931,  0.02059482],\n",
              "        [-0.01343144,  0.00077759,  0.04637302,  0.01438062,\n",
              "         -0.0496563 , -0.01425842,  0.01294878,  0.03001133,\n",
              "          0.01270897, -0.04096937,  0.00698727,  0.04919044,\n",
              "          0.03012586,  0.01675054, -0.04263177, -0.01903343,\n",
              "         -0.03522167, -0.01371257, -0.01738884, -0.02445426,\n",
              "         -0.04217076,  0.02698723,  0.0039505 , -0.00170387,\n",
              "          0.03346577, -0.04401766, -0.03518755, -0.04813578,\n",
              "          0.02521135, -0.00589389, -0.02302381, -0.03412719],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ],\n",
              "        [ 0.04204993, -0.04530725, -0.01713831,  0.00637757,\n",
              "         -0.00513697, -0.0076772 ,  0.0056512 , -0.01668831,\n",
              "         -0.03534585, -0.04459186, -0.01399169, -0.01570458,\n",
              "          0.01459069,  0.01242124, -0.02008538,  0.04014866,\n",
              "         -0.02789549,  0.04053891, -0.03762463, -0.04304496,\n",
              "         -0.01602163, -0.0257201 ,  0.04340554, -0.01302331,\n",
              "          0.0176718 , -0.04268553,  0.00923998,  0.04748816,\n",
              "         -0.01381711,  0.04202402, -0.03108749,  0.04209211]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the dateaset"
      ],
      "metadata": {
        "id": "74S_UQCZmCYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.review\n",
        "y = df.sentiment"
      ],
      "metadata": {
        "id": "SOXv9HqtqvoJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[y == \"positive\"] = 1\n",
        "y[y == \"negative\"] = 0\n",
        "y = np.asarray(y, np.float32).reshape((-1,1))"
      ],
      "metadata": {
        "id": "2YKs4B1gol92"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X[:1000]\n",
        "X_test = X[1000:]\n",
        "\n",
        "y_train = y[:1000]\n",
        "y_test = y[1000:]"
      ],
      "metadata": {
        "id": "h7wYrkhMn1Z1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulid the model"
      ],
      "metadata": {
        "id": "W3t9YQVm2Rx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dense model"
      ],
      "metadata": {
        "id": "li0gSOee2UFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bulid the Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(dtype=tf.string, shape=(1,)),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp63fZYTmO9w",
        "outputId": "ac85b0ce-ffbb-4b28-db19-b49ed37d9ded"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 32)          320000    \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 128)         4224      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 1)           129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Compile the model\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tTP0HNLQml9v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Fit / Train\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgY204KSnafd",
        "outputId": "2709d358-bd60-4c03-f107-6327c3695454"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 18s 495ms/step - loss: 0.6937 - accuracy: 0.5001 - val_loss: 0.6929 - val_accuracy: 0.5083\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 16s 515ms/step - loss: 0.6928 - accuracy: 0.5123 - val_loss: 0.6925 - val_accuracy: 0.5105\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6924 - accuracy: 0.5053 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 17s 532ms/step - loss: 0.6901 - accuracy: 0.5275 - val_loss: 0.6913 - val_accuracy: 0.5132\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6882 - accuracy: 0.5245 - val_loss: 0.6913 - val_accuracy: 0.5133\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44c445c040>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. RNN Model"
      ],
      "metadata": {
        "id": "-RvL1UPK2XG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bulid the Model\n",
        "model_rnn = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(dtype=tf.string, shape=(1,)),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),  # Simple RNN layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 2. Compile\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit\n",
        "model_rnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j5Hk4uQndsT",
        "outputId": "882f5c7a-2694-409f-a422-2d17ce30d5b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 54s 2s/step - loss: 0.6585 - accuracy: 0.6160 - val_loss: 0.6516 - val_accuracy: 0.6849\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.5614 - accuracy: 0.8580 - val_loss: 0.5768 - val_accuracy: 0.7512\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.4253 - accuracy: 0.8410 - val_loss: 0.5888 - val_accuracy: 0.7335\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.3400 - accuracy: 0.8880 - val_loss: 0.5280 - val_accuracy: 0.7555\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.2392 - accuracy: 0.9440 - val_loss: 0.6334 - val_accuracy: 0.7363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44c53b3400>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Transfer Learning Model\n",
        "\n",
        "We will use **`Google`**'s own **`universal-sentence-encoder`** model found [**Here**](https://tfhub.dev/google/universal-sentence-encoder/4)\n",
        "\n"
      ],
      "metadata": {
        "id": "dbgMIeuarpnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model\n",
        "                                        dtype=tf.string) # data type of inputs coming to the USE layer"
      ],
      "metadata": {
        "id": "TP_ajhHutMRA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7dV-FK3tdWV",
        "outputId": "40c71e30-c38c-45fc-9c97-1fd79f6cc5cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.6593 - accuracy: 0.6930 - val_loss: 0.6169 - val_accuracy: 0.7797\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 83s 3s/step - loss: 0.5596 - accuracy: 0.8200 - val_loss: 0.5245 - val_accuracy: 0.8047\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 57s 2s/step - loss: 0.4593 - accuracy: 0.8520 - val_loss: 0.4533 - val_accuracy: 0.8204\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 83s 3s/step - loss: 0.3898 - accuracy: 0.8650 - val_loss: 0.4134 - val_accuracy: 0.8265\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.3450 - accuracy: 0.8690 - val_loss: 0.3885 - val_accuracy: 0.8308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f447d43edd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([\"This is the best movie I ever saw in my entire life. just Wow.\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPy1_rKhuFml",
        "outputId": "12c923e2-c950-4487-e72d-61d93b080172"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 407ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8861213]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([\"I barely watched the movie, terrible plot, terrible acting, bad experience in general. Do not waste your money.\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFoIC2M1yw1-",
        "outputId": "53d83547-60f1-466b-8e62-968c5b6ca6ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02214688]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([\"I mean it alright, overrated if you want my opinion.\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT2V2M3Ty-NG",
        "outputId": "0fe373c4-1425-46c7-ecb6-cbf26b8fc702"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38793907]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zrt2Aws9zGKm"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}