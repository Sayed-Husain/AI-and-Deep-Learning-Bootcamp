{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Basics with TensorFlow\n"
      ],
      "metadata": {
        "id": "cr4t4MPR7CVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Deep Learning\n",
        "Deep Learning is a subset of machine learning that focuses on training artificial neural networks to perform tasks by simulating the human brain's neural structure. It has revolutionized various fields, including image and speech recognition, natural language processing, and more. **`TensorFlow`** and **`PyTorch`** are two of the most commonly used libraries for implementing deep learning models.\n",
        "\n",
        "It's worth noting that the design and development of **`TensorFlow`**, particularly its high-level API **`Keras`**, were inspired by the success and user-friendly nature of scikit-learn in the machine learning realm. This means that if you are already familiar with **`scikit-learn`**, transitioning to **`TensorFlow`** and **`Keras`** for deep learning will likely be smoother, as many concepts and conventions are shared between the two.\n",
        "\n",
        "In this notebook, we will cover the fundamental concepts of deep learning using **`TensorFlow`**, while also mentioning how some of these concepts can be applied using PyTorch. This assumes you are already familiar with the basics of machine learning using **`scikit-learn`**."
      ],
      "metadata": {
        "id": "SipV0QyI7KSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "0. **TensorFlow vs. PyTorch**\n",
        "\n",
        "1. **TensorFlow Basics**\n",
        "  * Tensors and Operations\n",
        "  * Automatic Differentiation\n",
        "\n",
        "\n",
        "\n",
        "2. **Building Neural Networks**\n",
        "\n",
        "  * Creating a Simple Neural Network\n",
        "  * Activation Functions\n",
        "  * Loss Functions\n",
        "  * Optimization Techniques\n",
        "\n",
        "\n",
        "\n",
        "3. **Training and Evaluating Models**\n",
        "\n",
        "  * Dataset Preparation\n",
        "  * Model Compilation\n",
        "  * Model Training\n",
        "  * Model Evaluation\n",
        "\n",
        "\n",
        "\n",
        "4. **Deep Learning Techniques**\n",
        "\n",
        "  * Convolutional Neural Networks (CNNs)\n",
        "  * Recurrent Neural Networks (RNNs)\n",
        "  * Transfer Learning"
      ],
      "metadata": {
        "id": "jS0hGfAm7FxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. TensorFlow vs. PyTorch\n",
        "\n"
      ],
      "metadata": {
        "id": "uvfq57NyHQwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow and PyTorch are two of the most widely used deep learning frameworks. Both provide extensive tools for building and training neural networks, but they have different design philosophies.\n",
        "\n",
        "- **TensorFlow**: Developed by Google, TensorFlow focuses on flexibility and production readiness. It offers both high-level APIs for quick model development (like Keras) and low-level APIs for fine-grained control over network architecture and optimization.\n",
        "\n",
        "- **PyTorch**: Developed by Facebook, PyTorch emphasizes dynamic computation graphs. It provides a more intuitive interface for research and experimentation, making it popular among researchers. Its dynamic nature allows for easier debugging and prototyping.\n",
        "\n",
        "The choice between TensorFlow and PyTorch often depends on factors like the task at hand, personal preference, and the development context."
      ],
      "metadata": {
        "id": "Hi9PZVgfHVWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. TensorFlow Basics\n"
      ],
      "metadata": {
        "id": "qDsAgDTM7vKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors: The Building Blocks\n",
        "At the core of TensorFlow are tensors, which are multi-dimensional arrays used to represent data. Tensors can have different ranks (number of dimensions) and shapes. The following are some common tensor types:\n",
        "\n",
        "* **Scalar (Rank 0):** A single value, e.g., a constant or a single pixel intensity.\n",
        "* **Vector (Rank 1):** A one-dimensional array, e.g., a list of values.\n",
        "* **Matrix (Rank 2):** A two-dimensional array, e.g., an image or a table of data.\n",
        "* **Tensor (Rank > 2):** A multi-dimensional array, e.g., a color image with height, width, and channels.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vWyEKvBs7mWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with Tensors\n",
        "Creating tensors is simple in TensorFlow:"
      ],
      "metadata": {
        "id": "w4nED8M6-7_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "scalar = tf.constant(5)             # A scalar\n",
        "vector = tf.constant([1, 2, 3])     # A vector\n",
        "matrix = tf.constant([[1, 2], [3, 4]])  # A matrix\n",
        "```"
      ],
      "metadata": {
        "id": "5SKGEJGO7zTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also create tensors from existing numpy arrays:\n",
        "\n"
      ],
      "metadata": {
        "id": "eVw0EpwE_Gau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\n",
        "numpy_array = np.array([1, 2, 3])\n",
        "tensor_from_numpy = tf.convert_to_tensor(numpy_array)\n",
        "```"
      ],
      "metadata": {
        "id": "5QBXkeLP_JYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operations on Tensors\n",
        "Tensors support various operations, similar to numpy arrays:"
      ],
      "metadata": {
        "id": "Yyr87OHd_QzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "tensor_1 = tf.constant([[1, 2], [3, 4]])\n",
        "tensor_2 = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Element-wise addition\n",
        "result_add = tf.add(tensor_1, tensor_2)\n",
        "\n",
        "# Element-wise multiplication\n",
        "result_mul = tf.multiply(tensor_1, tensor_2)\n",
        "\n",
        "# Matrix multiplication\n",
        "result_matmul = tf.matmul(tensor_1, tensor_2)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "CYkOCPIh_eSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep in mind that TensorFlow operations are lazy; they are only executed when needed. To retrieve the actual values, you can use the .numpy() method:"
      ],
      "metadata": {
        "id": "j1bbK0td_kaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "numpy_result = result_add.numpy()\n",
        "```"
      ],
      "metadata": {
        "id": "bMIttrlA_lZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building Neural Networks\n"
      ],
      "metadata": {
        "id": "7_4htLLg8Gbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Artifical Neural Network](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20230602113310/Neural-Networks-Architecture.png)"
      ],
      "metadata": {
        "id": "bh8QGRfM2nao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Simple Neural Network\n",
        "Neural networks in TensorFlow can be easily built using the tf.keras API. Here's an example of a simple feedforward neural network:"
      ],
      "metadata": {
        "id": "6JCoDz0_8PFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_size,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(output_size, activation='softmax') # Ouput layer\n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "XkJ17tJu8Rx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation Functions\n",
        "Activation functions introduce non-linearity to the network. Common activation functions include ReLU (Rectified Linear Activation), sigmoid, and tanh."
      ],
      "metadata": {
        "id": "CiMrpDDS8a2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "tf.keras.layers.Dense(64, activation='relu')\n",
        "```"
      ],
      "metadata": {
        "id": "iXMpq99f8gLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Functions\n",
        "Loss functions quantify the difference between predicted and actual values. Common loss functions are mean squared error (MSE) for regression and categorical cross-entropy for classification."
      ],
      "metadata": {
        "id": "u9vOusrF8jas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "```"
      ],
      "metadata": {
        "id": "oaeYeCfu8msJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization Techniques\n",
        "Optimizers adjust model parameters during training to minimize the loss function. Examples include Adam, SGD (Stochastic Gradient Descent), and RMSprop."
      ],
      "metadata": {
        "id": "0uTwzVuV8rDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "```"
      ],
      "metadata": {
        "id": "TfRsJ9au8xAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training and Evaluating Models\n"
      ],
      "metadata": {
        "id": "jOkq-3fe81T9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preparation\n",
        "Data should be prepared in tensors before training. You can use the tf.data API to load, shuffle, and preprocess data efficiently."
      ],
      "metadata": {
        "id": "iaUa0b9R8341"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Xhxzbr_i860W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Compilation\n",
        "Before training, compile the model by specifying the optimizer, loss function, and metrics to monitor."
      ],
      "metadata": {
        "id": "dzAMSgej8_jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "```"
      ],
      "metadata": {
        "id": "ACaHAWuk9HqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "Train the model using the prepared dataset and the fit method."
      ],
      "metadata": {
        "id": "0Q4DX9RF9K5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "model.fit(dataset, epochs=num_epochs, validation_data=(X_val, y_val))\n",
        "```"
      ],
      "metadata": {
        "id": "QOIudjak9N5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n",
        "Evaluate the trained model's performance on the test dataset."
      ],
      "metadata": {
        "id": "wM4U0HRt9RGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "```"
      ],
      "metadata": {
        "id": "k8kq_RH49XJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Deep Learning Techniques\n"
      ],
      "metadata": {
        "id": "8wMW9qWX9ZNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Convolutional Neural Networks (CNNs)\n",
        "CNNs are used for image-related tasks. They consist of convolutional layers for feature extraction and pooling layers for downsampling."
      ],
      "metadata": {
        "id": "v_QNG-Ot9dil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "Lqg-YYzd9fmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Recurrent Neural Networks (RNNs)\n",
        "RNNs are suitable for sequential data like time series or text. They process sequences step by step while maintaining hidden states."
      ],
      "metadata": {
        "id": "YMNxGSfJ9i4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "model = Sequential([\n",
        "    SimpleRNN(64, activation='relu', input_shape=(time_steps, features)),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "uNzQQQ_t9mUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Transfer Learning\n",
        "Transfer learning leverages pre-trained models for new tasks. You can fine-tune a pre-trained model on your specific dataset."
      ],
      "metadata": {
        "id": "KJeai03A9qGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "2jcTkPJ39uCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "This notebook provided an introduction to deep learning using TensorFlow. We covered basic TensorFlow operations with tensors, building neural networks, training, evaluation, and some advanced techniques. Deep learning is a vast field, and this notebook serves as a foundation for your further exploration. Happy learning and experimenting!"
      ],
      "metadata": {
        "id": "iEgV002b9zaX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TX2LMmHZ_3EJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}